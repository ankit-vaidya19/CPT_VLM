[2024-07-10 10:33:24,418] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading LLaVA from base model...
Traceback (most recent call last):
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/transformers/utils/hub.py", line 385, in cached_file
    resolved_file = hf_hub_download(
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/avaidya7/checkpoints/llava-v1.5-7b-tv100_nola'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/avaidya7/CPT_VLM/scripts/merge_lora_weights.py", line 27, in <module>
    merge_lora(args)
  File "/home/avaidya7/CPT_VLM/scripts/merge_lora_weights.py", line 11, in merge_lora
    tokenizer, model, image_processor, context_len = load_pretrained_model(
  File "/home/avaidya7/CPT_VLM/llava/model/builder.py", line 152, in load_pretrained_model
    cfg_pretrained = AutoConfig.from_pretrained(model_path)
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1100, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/transformers/configuration_utils.py", line 634, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/avaidya7/.conda/envs/llava/lib/python3.10/site-packages/transformers/utils/hub.py", line 450, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/home/avaidya7/checkpoints/llava-v1.5-7b-tv100_nola'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
